※情報として少し古いですが、時間の関係上メンテはしてません

## 概要
- RSSよりデータを収集し、データをDBに記録する。

## 参考資料
- [3Q技術キュレーションサービス_要件機能整理 > 記事収集機能](https://docs.google.com/spreadsheets/d/155nc4Wu7NXVLMKXLMqCQahpgcdRng_H_izJ9feed(DB)ss0iw/edit?gid=2059564945#gid=2059564945&range=12:12)

- [収集対象](https://github.com/yamadashy/tech-blog-rss-feed/blob/c8300c582e76c95f1123d6519d0ded51202fffb5/src/resources/feed-info-list.ts#L30)

- [RSSタグ一覧](https://docs.google.com/spreadsheets/d/155nc4Wu7NXVLMKXLMqCQahpgcdRng_H_izJ9Dbss0iw/edit?gid=614395705#gid=614395705&range=1:18)


## 技術選定
- 記事収集機能: go
- カテゴリ判定: python(機械学習ライブラリ使うので)

## 残論点① categotyの判定
### 1stリリース
- [こちらのワード](https://docs.google.com/spreadsheets/d/155nc4Wu7NXVLMKXLMqCQahpgcdRng_H_izJ9Dbss0iw/edit?gid=651602187#gid=651602187)でラベリング

### 2stリリース
- 機械学習系のライブラリを活用して判定する:
  - [キーワードを使った文章のカテゴリー判定](https://qiita.com/zawa_tech/items/a215d16fd2dc833f4e0c)
  - [参考](https://developers.wonderpla.net/entry/2017/10/10/110000)
  - Google ColaboratoryでAPIサーバー立てることもできそう: [参考](https://qiita.com/k_0214/items/dcf14c74779eb9839577)
    - [ChatGPTのAPIをGoogle colabで使い倒してみる](https://note.com/nero1014/n/n09a2ce7843b8)
- カテゴリの信憑性
  - ユーザーがいいねをした時にその判定を信憑する
  - 流入数やセッション数で判定する？

## 記事収集機能設計
### 記事収集
* トリガー
  * 3hに1回
  * 毎日7:00~18:00まで

```mermaid
sequenceDiagram
  participant EventBrige
  participant lambda(記事収集)
  Note left of lambda(記事収集): go
  participant feed(DB)
  participant feed(article)
  participant 収集対象のサイト
  participant lambda(カテゴリ判定)
  Note left of lambda(カテゴリ判定): python(2ndリリース)
  EventBrige ->>+ lambda(記事収集): POST<br> /api/v1/rss/feeds/fetch
  lambda(記事収集) ->>+ lambda(記事収集): 収集対象のサイト一覧取得
  loop 収集対象のサイト数
    lambda(記事収集) ->>+ 収集対象のサイト: feed情報取得
    収集対象のサイト -->>- lambda(記事収集): feed情報
    lambda(記事収集) ->>+ feed(DB): feed情報を取得
    feed(DB) ->> feed(DB): titleとlinkを元にfeed情報取得
    feed(DB) -->>- lambda(記事収集): feed情報
    alt feed情報がない
      lambda(記事収集) ->>+ feed(DB): feed情報を新規保存
      feed(DB) -->>- lambda(記事収集): '
      lambda(記事収集) ->>+ lambda(記事収集): 一括更新配列にfeed情報を入れる
    else feed情報がある
      alt lastBuildDateが最新である場合
        lambda(記事収集) ->>+ feed(DB): 対象feedのlastBuildDateを更新
        feed(DB) -->>- lambda(記事収集): '
      else lastBuildDateが最新ではない
        lambda(記事収集) ->>+ lambda(記事収集): skip
      end
  end
  loop 一括更新対象のfeed数分
    loop feedの中にあるitemの数分
    Note right of lambda(記事収集): 1stリリース
    lambda(記事収集) ->> lambda(記事収集): titleから文字列を取得し、定義済データでカテゴリを判定
    lambda(記事収集) ->>+ feed(article): 記事をupsert
    feed(article) ->> feed(article): 記事の一意識別子であるguidを元にupsert
    feed(article) -->>- lambda(記事収集): '
    end
  end
  Note right of lambda(記事収集): 記事のフィルタリングどうするか？<br>1stリリースではなくても良いか？
  Note right of lambda(記事収集): 記事の評価どうするか？<br>1stリリースではなくても良いか？
end

```

## DB設計
```mermaid
erDiagram
    feeds {
        INT id PK "NOT NULL"
        VARCHAR(255) title "NOT NULL RSSフィードのタイトル"
        TEXT link "NOT NULL フィードのURL"
        TEXT description "フィードの説明"
        TEXT category "チャンネルのカテゴリ"
        json image "チャンネルのimage情報"
        VARCHAR(10) language "NOT NULL フィードの言語コード"
        DATETIME last_build_date "NOT NULL フィードが最後に更新された日時"
        TIMESTAMP created_at
        TIMESTAMP updated_at
    }

    articles {
        INT id PK "NOT NULL"
        INT feed_id FK "NOT NULL"
        INT category_id FK "NOT NULL"
        VARCHAR(255) title "NOT NULL 記事のタイトル"
        TEXT link "NOT NULL 記事へのリンク"
        TEXT description "記事の内容や概要"
        DATETIME pub_date "NOT NULL 記事の公開日時"
        VARCHAR(255) guid "NOT NULL 記事の一意な識別子"
        TIMESTAMP created_at
        TIMESTAMP updated_at
    }

    tags {
        INT id PK "NOT NULL"
        VARCHAR(255) name "NOT NULL,UNIQUE,カテゴリ名"
        INT category_id FK "NOT NULL"
    }

    article_tags {
        INT id PK "NOT NULL"
        INT article_id FK "NOT NULL"
        INT tag_id FK "NOT NULL"
    }

    categories {
        INT id PK "NOT NULL"
        VARCHAR(255) name "NOT NULL,UNIQUE,カテゴリ名"
    }

    feeds ||--o{ articles : ""
    articles ||--o{ article_tags : ""
    article_tags }o--|| tags : ""
    articles }o--|| categories : ""
```
